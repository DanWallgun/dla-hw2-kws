{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_lhrn5O-qUYZ"
   },
   "source": [
    "# Import and misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "meO-Mp9jiAFC"
   },
   "outputs": [],
   "source": [
    "# Instal latest torch and torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bbUpoArCqUYa"
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, Union, List, Callable, Optional\n",
    "from tqdm import tqdm\n",
    "from itertools import islice\n",
    "import pathlib\n",
    "import dataclasses\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import distributions\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "import torchaudio\n",
    "from IPython import display as display_\n",
    "\n",
    "def set_random_seed(seed=42):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    # random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "812GwLfqqUYf"
   },
   "source": [
    "# Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1DuQIyRqUYf"
   },
   "source": [
    "In this notebook we will implement a model for finding a keyword in a stream.\n",
    "\n",
    "We will implement the version with CRNN because it is easy and improves the model. \n",
    "(from https://www.dropbox.com/s/22ah2ba7dug6pzw/KWS_Attention.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8PdhApeEh9pH"
   },
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class TaskConfig:\n",
    "    keyword: str = 'sheila'  # We will use 1 key word -- 'sheila'\n",
    "    batch_size: int = 128\n",
    "    num_workers: int = 2\n",
    "    learning_rate: float = 3e-4\n",
    "    weight_decay: float = 1e-5\n",
    "    num_epochs: int = 20\n",
    "    n_mels: int = 40\n",
    "    cnn_out_channels: int = 8\n",
    "    kernel_size: Tuple[int, int] = (5, 20)\n",
    "    stride: Tuple[int, int] = (2, 8)\n",
    "    hidden_size: int = 64\n",
    "    gru_num_layers: int = 2\n",
    "    bidirectional: bool = False\n",
    "    num_classes: int = 2\n",
    "    sample_rate: int = 16000\n",
    "    device: torch.device = torch.device(\n",
    "        'cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    max_window_length: int = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KA1gPmE1h9pI"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y2N8zcx9MF1X",
    "outputId": "38e449a6-dd79-4eb1-e268-57c72ce06af5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-06 23:12:09--  http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 2a00:1450:400f:801::2010, 74.125.131.128\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|2a00:1450:400f:801::2010|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1489096277 (1,4G) [application/gzip]\n",
      "Saving to: ‘speech_commands_v0.01.tar.gz’\n",
      "\n",
      "gz                   51%[=========>          ] 734,69M  24,2MB/s    eta 26s    ^C\n",
      "mkdir: speech_commands: File exists\n"
     ]
    }
   ],
   "source": [
    "!wget http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz -O speech_commands_v0.01.tar.gz\n",
    "!mkdir speech_commands && tar -C speech_commands -xvzf speech_commands_v0.01.tar.gz 1> log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "12wBTK0mNUsG"
   },
   "outputs": [],
   "source": [
    "class SpeechCommandDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        transform: Optional[Callable] = None,\n",
    "        path2dir: str = None,\n",
    "        keywords: Union[str, List[str]] = None,\n",
    "        csv: Optional[pd.DataFrame] = None\n",
    "    ):        \n",
    "        self.transform = transform\n",
    "\n",
    "        if csv is None:\n",
    "            path2dir = pathlib.Path(path2dir)\n",
    "            keywords = keywords if isinstance(keywords, list) else [keywords]\n",
    "            \n",
    "            all_keywords = [\n",
    "                p.stem for p in path2dir.glob('*')\n",
    "                if p.is_dir() and not p.stem.startswith('_')\n",
    "            ]\n",
    "\n",
    "            triplets = []\n",
    "            for keyword in all_keywords:\n",
    "                paths = (path2dir / keyword).rglob('*.wav')\n",
    "                if keyword in keywords:\n",
    "                    for path2wav in paths:\n",
    "                        triplets.append((path2wav.as_posix(), keyword, 1))\n",
    "                else:\n",
    "                    for path2wav in paths:\n",
    "                        triplets.append((path2wav.as_posix(), keyword, 0))\n",
    "            \n",
    "            self.csv = pd.DataFrame(\n",
    "                triplets,\n",
    "                columns=['path', 'keyword', 'label']\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            self.csv = csv\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        instance = self.csv.iloc[index]\n",
    "\n",
    "        path2wav = instance['path']\n",
    "        wav, sr = torchaudio.load(path2wav)\n",
    "        wav = wav.sum(dim=0)\n",
    "        \n",
    "        if self.transform:\n",
    "            wav = self.transform(wav)\n",
    "\n",
    "        return {\n",
    "            'wav': wav,\n",
    "            'keywors': instance['keyword'],\n",
    "            'label': instance['label']\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-1rVkT81Pk90"
   },
   "outputs": [],
   "source": [
    "dataset = SpeechCommandDataset(\n",
    "    path2dir='speech_commands', keywords=TaskConfig.keyword\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "DFwhAXdfQLIA",
    "outputId": "a69cc100-d976-4ba6-f27c-cf6b1e7fc5c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>keyword</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17818</th>\n",
       "      <td>speech_commands/no/1b4c9b89_nohash_3.wav</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15434</th>\n",
       "      <td>speech_commands/dog/3cfc6b3a_nohash_0.wav</td>\n",
       "      <td>dog</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6420</th>\n",
       "      <td>speech_commands/cat/1678e6f1_nohash_0.wav</td>\n",
       "      <td>cat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54052</th>\n",
       "      <td>speech_commands/yes/6c968bd9_nohash_1.wav</td>\n",
       "      <td>yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26021</th>\n",
       "      <td>speech_commands/stop/3e31dffe_nohash_3.wav</td>\n",
       "      <td>stop</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             path keyword  label\n",
       "17818    speech_commands/no/1b4c9b89_nohash_3.wav      no      0\n",
       "15434   speech_commands/dog/3cfc6b3a_nohash_0.wav     dog      0\n",
       "6420    speech_commands/cat/1678e6f1_nohash_0.wav     cat      0\n",
       "54052   speech_commands/yes/6c968bd9_nohash_1.wav     yes      0\n",
       "26021  speech_commands/stop/3e31dffe_nohash_3.wav    stop      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.csv.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N494kNzl2sPJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUxfDJw1qUYi"
   },
   "source": [
    "### Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "dkmkxPWQqUYe"
   },
   "outputs": [],
   "source": [
    "class AugsCreation:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.background_noises = [\n",
    "            'speech_commands/_background_noise_/white_noise.wav',\n",
    "            'speech_commands/_background_noise_/dude_miaowing.wav',\n",
    "            'speech_commands/_background_noise_/doing_the_dishes.wav',\n",
    "            'speech_commands/_background_noise_/exercise_bike.wav',\n",
    "            'speech_commands/_background_noise_/pink_noise.wav',\n",
    "            'speech_commands/_background_noise_/running_tap.wav'\n",
    "        ]\n",
    "\n",
    "        self.noises = [\n",
    "            torchaudio.load(p)[0].squeeze()\n",
    "            for p in self.background_noises\n",
    "        ]\n",
    "\n",
    "    def add_rand_noise(self, audio):\n",
    "\n",
    "        # randomly choose noise\n",
    "        noise_num = torch.randint(low=0, high=len(\n",
    "            self.background_noises), size=(1,)).item()\n",
    "        noise = self.noises[noise_num]\n",
    "\n",
    "        noise_level = torch.Tensor([1])  # [0, 40]\n",
    "\n",
    "        noise_energy = torch.norm(noise)\n",
    "        audio_energy = torch.norm(audio)\n",
    "        alpha = (audio_energy / noise_energy) * \\\n",
    "            torch.pow(10, -noise_level / 20)\n",
    "\n",
    "        start = torch.randint(\n",
    "            low=0,\n",
    "            high=max(int(noise.size(0) - audio.size(0) - 1), 1),\n",
    "            size=(1,)\n",
    "        ).item()\n",
    "        noise_sample = noise[start: start + audio.size(0)]\n",
    "\n",
    "        audio_new = audio + alpha * noise_sample\n",
    "        audio_new.clamp_(-1, 1)\n",
    "        return audio_new\n",
    "\n",
    "    def __call__(self, wav):\n",
    "        aug_num = torch.randint(low=0, high=4, size=(1,)).item()   # choose 1 random aug from augs\n",
    "        augs = [\n",
    "            lambda x: x,\n",
    "            lambda x: (x + distributions.Normal(0, 0.01).sample(x.size())).clamp_(-1, 1),\n",
    "            lambda x: torchaudio.transforms.Vol(.25)(x),\n",
    "            lambda x: self.add_rand_noise(x)\n",
    "        ]\n",
    "\n",
    "        return augs[aug_num](wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ClWThxyYh9pM"
   },
   "outputs": [],
   "source": [
    "set_random_seed()\n",
    "indexes = torch.randperm(len(dataset))\n",
    "train_indexes = indexes[:int(len(dataset) * 0.8)]\n",
    "val_indexes = indexes[int(len(dataset) * 0.8):]\n",
    "\n",
    "train_df = dataset.csv.iloc[train_indexes].reset_index(drop=True)\n",
    "val_df = dataset.csv.iloc[val_indexes].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "PDPLht5fqUYe"
   },
   "outputs": [],
   "source": [
    "# Sample is a dict of utt, word and label\n",
    "train_set = SpeechCommandDataset(csv=train_df, transform=AugsCreation())\n",
    "val_set = SpeechCommandDataset(csv=val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mmrJd8WIhkLP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vbPDqd6qUYj"
   },
   "source": [
    "### Sampler for oversampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rfnjRKo2qUYj"
   },
   "outputs": [],
   "source": [
    "# We should provide to WeightedRandomSampler _weight for every sample_; by default it is 1/len(target)\n",
    "\n",
    "def get_sampler(target):\n",
    "    class_sample_count = np.array(\n",
    "        [len(np.where(target == t)[0]) for t in np.unique(target)])   # for every class count it's number of occ.\n",
    "    weight = 1. / class_sample_count\n",
    "    samples_weight = np.array([weight[t] for t in target])\n",
    "    samples_weight = torch.from_numpy(samples_weight)\n",
    "    samples_weigth = samples_weight.float()\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "UM8gLmHeqUYj"
   },
   "outputs": [],
   "source": [
    "train_sampler = get_sampler(train_set.csv['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lyBqbxp0h9pO"
   },
   "outputs": [],
   "source": [
    "class Collator:\n",
    "    \n",
    "    def __call__(self, data):\n",
    "        wavs = []\n",
    "        labels = []    \n",
    "\n",
    "        for el in data:\n",
    "            wavs.append(el['wav'])\n",
    "            labels.append(el['label'])\n",
    "\n",
    "        # torch.nn.utils.rnn.pad_sequence takes list(Tensors) and returns padded (with 0.0) Tensor\n",
    "        wavs = pad_sequence(wavs, batch_first=True)    \n",
    "        labels = torch.Tensor(labels).long()\n",
    "        return wavs, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8G9xPRVqUYk"
   },
   "source": [
    "###  Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "6wGBMcQiqUYk"
   },
   "outputs": [],
   "source": [
    "# Here we are obliged to use shuffle=False because of our sampler with randomness inside.\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=TaskConfig.batch_size,\n",
    "                          shuffle=False, collate_fn=Collator(),\n",
    "                          sampler=train_sampler,\n",
    "                          num_workers=TaskConfig.num_workers, pin_memory=True)\n",
    "\n",
    "val_loader = DataLoader(val_set, batch_size=TaskConfig.batch_size,\n",
    "                        shuffle=False, collate_fn=Collator(),\n",
    "                        num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTlsn6cpqUYk"
   },
   "source": [
    "### Creating MelSpecs on GPU for speeeed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "pRXMt6it56fW"
   },
   "outputs": [],
   "source": [
    "class LogMelspec(nn.Module):\n",
    "\n",
    "    def __init__(self, is_train, config):\n",
    "        super().__init__()\n",
    "        # with augmentations\n",
    "        if is_train:\n",
    "            self.melspec = nn.Sequential(\n",
    "                torchaudio.transforms.MelSpectrogram(\n",
    "                    sample_rate=config.sample_rate,\n",
    "                    n_fft=400,\n",
    "                    win_length=400,\n",
    "                    hop_length=160,\n",
    "                    n_mels=config.n_mels\n",
    "                ),\n",
    "                torchaudio.transforms.FrequencyMasking(freq_mask_param=15),\n",
    "                torchaudio.transforms.TimeMasking(time_mask_param=35),\n",
    "            ).to(config.device)\n",
    "\n",
    "        # no augmentations\n",
    "        else:\n",
    "            self.melspec = torchaudio.transforms.MelSpectrogram(\n",
    "                sample_rate=config.sample_rate,\n",
    "                n_fft=400,\n",
    "                win_length=400,\n",
    "                hop_length=160,\n",
    "                n_mels=config.n_mels\n",
    "            ).to(config.device)\n",
    "\n",
    "    # def __call__(self, batch):\n",
    "    def forward(self, batch):\n",
    "        # already on device\n",
    "        return torch.log(self.melspec(batch).clamp_(min=1e-9, max=1e9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Pqkz4_gn8BiF"
   },
   "outputs": [],
   "source": [
    "melspec_train = LogMelspec(is_train=True, config=TaskConfig)\n",
    "melspec_val = LogMelspec(is_train=False, config=TaskConfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zoAxmihY8yxr"
   },
   "source": [
    "### Quality measurment functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "euwD1UyuqUYk"
   },
   "outputs": [],
   "source": [
    "# FA - true: 0, model: 1\n",
    "# FR - true: 1, model: 0\n",
    "\n",
    "def count_FA_FR(preds, labels):\n",
    "    FA = torch.sum(preds[labels == 0])\n",
    "    FR = torch.sum(labels[preds == 0])\n",
    "    \n",
    "    # torch.numel - returns total number of elements in tensor\n",
    "    return FA.item() / torch.numel(preds), FR.item() / torch.numel(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "YHBUrkT1qUYk"
   },
   "outputs": [],
   "source": [
    "def get_au_fa_fr(probs, labels):\n",
    "    sorted_probs, _ = torch.sort(probs)\n",
    "    sorted_probs = torch.cat((torch.Tensor([0]), sorted_probs, torch.Tensor([1])))\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "        \n",
    "    FAs, FRs = [], []\n",
    "    print('sorted_probs', len(sorted_probs))\n",
    "    for prob in tqdm(sorted_probs):\n",
    "        preds = (probs >= prob) * 1\n",
    "        FA, FR = count_FA_FR(preds, labels)        \n",
    "        FAs.append(FA)\n",
    "        FRs.append(FR)\n",
    "    # plt.plot(FAs, FRs)\n",
    "    # plt.show()\n",
    "\n",
    "    # ~ area under curve using trapezoidal rule\n",
    "    return -np.trapz(FRs, x=FAs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcEP5cEZqUYl"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2cP_pFIsy5p2",
    "outputId": "c524e70e-e35b-4234-d722-c081d677a741"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(5, 20), stride=(2, 8))\n",
       "    (1): Flatten(start_dim=1, end_dim=2)\n",
       "  )\n",
       "  (gru): GRU(144, 64, num_layers=2, batch_first=True, dropout=0.1)\n",
       "  (attention): Attention(\n",
       "    (energy): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Attention(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.energy = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        energy = self.energy(input)\n",
    "        alpha = torch.softmax(energy, dim=-2)\n",
    "        return (input * alpha).sum(dim=-2)\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "\n",
    "    def __init__(self, config: TaskConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1, out_channels=config.cnn_out_channels,\n",
    "                kernel_size=config.kernel_size, stride=config.stride\n",
    "            ),\n",
    "            nn.Flatten(start_dim=1, end_dim=2),\n",
    "        )\n",
    "\n",
    "        self.conv_out_frequency = (config.n_mels - config.kernel_size[0]) // \\\n",
    "            config.stride[0] + 1\n",
    "        \n",
    "        self.gru = nn.GRU(\n",
    "            input_size=self.conv_out_frequency * config.cnn_out_channels,\n",
    "            hidden_size=config.hidden_size,\n",
    "            num_layers=config.gru_num_layers,\n",
    "            dropout=0.1,\n",
    "            bidirectional=config.bidirectional,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.attention = Attention(config.hidden_size)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_classes)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input = input.unsqueeze(dim=1)\n",
    "        # print(input.shape)\n",
    "        conv_output = self.conv(input).transpose(-1, -2)\n",
    "        gru_output, _ = self.gru(conv_output)\n",
    "        contex_vector = self.attention(gru_output)\n",
    "        output = self.classifier(contex_vector)\n",
    "        return output\n",
    "\n",
    "config = TaskConfig()\n",
    "model = CRNN(config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "DmmSFvWaqUYn"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, opt, loader, log_melspec, device):\n",
    "    model.train()\n",
    "    for i, (batch, labels) in tqdm(enumerate(loader), total=len(loader)):\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        batch = log_melspec(batch)\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # run model # with autocast():\n",
    "        logits = model(batch)\n",
    "        # we need probabilities so we use softmax & CE separately\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "        # logging\n",
    "        argmax_probs = torch.argmax(probs, dim=-1)\n",
    "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
    "        acc = torch.sum(argmax_probs == labels) / torch.numel(argmax_probs)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "UIeRbn4tqUYo"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validation(model, loader, log_melspec, device):\n",
    "    model.eval()\n",
    "\n",
    "    val_losses, accs, FAs, FRs = [], [], [], []\n",
    "    all_probs, all_labels = [], []\n",
    "    for i, (batch, labels) in tqdm(enumerate(loader)):\n",
    "        batch, labels = batch.to(device), labels.to(device)\n",
    "        batch = log_melspec(batch)\n",
    "\n",
    "        output = model(batch)\n",
    "        # we need probabilities so we use softmax & CE separately\n",
    "        probs = F.softmax(output, dim=-1)\n",
    "        loss = F.cross_entropy(output, labels)\n",
    "\n",
    "        # logging\n",
    "        argmax_probs = torch.argmax(probs, dim=-1)\n",
    "        all_probs.append(probs[:, 1].cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "        val_losses.append(loss.item())\n",
    "        accs.append(\n",
    "            torch.sum(argmax_probs == labels).item() /  # ???\n",
    "            torch.numel(argmax_probs)\n",
    "        )\n",
    "        FA, FR = count_FA_FR(argmax_probs, labels)\n",
    "        FAs.append(FA)\n",
    "        FRs.append(FR)\n",
    "\n",
    "    # area under FA/FR curve for whole loader\n",
    "    au_fa_fr = get_au_fa_fr(torch.cat(all_probs, dim=0).cpu(), all_labels)\n",
    "    return au_fa_fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "PpyvKwp0k3IU"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSNW-nZCJ4Q0"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q8sVpHNoocgA",
    "outputId": "cc436646-5321-4ce4-8615-bdcec4bd7903"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRNN(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(5, 20), stride=(2, 8))\n",
      "    (1): Flatten(start_dim=1, end_dim=2)\n",
      "  )\n",
      "  (gru): GRU(144, 32, num_layers=2, batch_first=True, dropout=0.1)\n",
      "  (attention): Attention(\n",
      "    (energy): Sequential(\n",
      "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=32, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "set_random_seed()\n",
    "\n",
    "config = TaskConfig(hidden_size=32)\n",
    "model = CRNN(config).to(config.device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "opt = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config.learning_rate,\n",
    "    weight_decay=config.weight_decay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zedXm9dmINAE",
    "outputId": "90f6f7b3-680f-41af-ddc1-45ce55ca9782"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25387"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vt2kjqC-IobK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "32oooz4lqUYo",
    "outputId": "085f2a7a-bbde-4162-b806-96f00612fbc4"
   },
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "\n",
    "for n in range(TaskConfig.num_epochs):\n",
    "\n",
    "    train_epoch(model, opt, train_loader,\n",
    "                melspec_train, config.device)\n",
    "\n",
    "    au_fa_fr = validation(model, val_loader,\n",
    "                          melspec_val, config.device)\n",
    "    history['val_metric'].append(au_fa_fr)\n",
    "\n",
    "    clear_output()\n",
    "    plt.plot(history['val_metric'])\n",
    "    plt.ylabel('Metric')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    print('END OF EPOCH', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WBkTUHZcVugz",
    "outputId": "09038fa8-9b42-4fd4-a06c-42450429b909"
   },
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRZB9KXyVvfa"
   },
   "source": [
    "### Reproduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t55FUkOGh9pT",
    "outputId": "f130e436-bb0c-4e54-f48b-5624409e9f0f"
   },
   "outputs": [],
   "source": [
    "history = defaultdict(list)\n",
    "set_random_seed()\n",
    "config = TaskConfig(hidden_size=32)\n",
    "model = CRNN(config).to(config.device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "opt = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config.learning_rate,\n",
    "    weight_decay=config.weight_decay\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "RqGOlKZbVt6j",
    "outputId": "1868fd44-1fb1-419f-b0dc-e3cf96546936"
   },
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "\n",
    "for n in range(TaskConfig.num_epochs):\n",
    "\n",
    "    train_epoch(model, opt, train_loader,\n",
    "                melspec_train, config.device)\n",
    "\n",
    "    au_fa_fr = validation(model, val_loader,\n",
    "                          melspec_val, config.device)\n",
    "    history['val_metric'].append(au_fa_fr)\n",
    "\n",
    "    clear_output()\n",
    "    plt.plot(history['val_metric'])\n",
    "    plt.ylabel('Metric')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    print('END OF EPOCH', n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "52G9D8SDV1Qa",
    "outputId": "8d791b14-a4d7-43c3-a090-5a967ba23809"
   },
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtmPf1pjDZgk",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пишем обёртку, которую затем сконвертируем в jit и подадим в stream.py. Поддерживаем кэш и обновляем приходящими чанками. За основу берем модель model, которую подаём как параметр и которая должна состоять из свёртки conv, gru-слоя, attention и classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 137
    },
    "id": "7ninnyveDdZw",
    "outputId": "cde5df8f-c1c1-49f0-ee37-0eb942f6e204"
   },
   "outputs": [],
   "source": [
    "class PewDiePie(nn.Module):\n",
    "    def __init__(self, model, config, melspec):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        # self.config = config\n",
    "        self.time_ks = config.kernel_size[1]\n",
    "        self.max_window_length = 402 * config.max_window_length * 2\n",
    "        self.max_gru_length = config.max_window_length\n",
    "        \n",
    "        self.melspec = melspec\n",
    "        self.melspec_window_size_half = 201\n",
    "\n",
    "        self.spec_cache = None  # mel spec\n",
    "        self.gru_cache = None\n",
    "        self.gru_h = torch.zeros(config.gru_num_layers, 1, config.hidden_size)\n",
    "        self.attn_cache = None\n",
    "        self.probs = torch.zeros(1)\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def stream(self, input):\n",
    "        input = input.unsqueeze(dim=1)\n",
    "        if self.spec_cache is None:\n",
    "            self.spec_cache = input\n",
    "        else:\n",
    "            self.spec_cache = torch.cat((self.spec_cache, input), dim=-1)\n",
    "        # time_ks = self.config.kernel_size[1]\n",
    "        # print(f'{self.spec_cache.size()=}\\t{time_ks=}')\n",
    "        if self.spec_cache.size(-1) < self.time_ks:\n",
    "            return None\n",
    "        if self.spec_cache.size(1) > self.max_window_length:\n",
    "            self.spec_cache = self.spec_cache[:,-self.max_window_length:,:]\n",
    "        self.spec_cache = self.spec_cache[..., -self.time_ks:]\n",
    "        x = self.model.conv(self.spec_cache).transpose(-1, -2)\n",
    "        x, self.gru_h = self.model.gru(x, self.gru_h)\n",
    "        if self.gru_cache is None:\n",
    "            self.gru_cache = x\n",
    "        else:\n",
    "            self.gru_cache = torch.cat((self.gru_cache, x), dim=1)\n",
    "        if self.gru_cache.size(1) > self.max_gru_length:\n",
    "            self.gru_cache = self.gru_cache[:,1:,:]\n",
    "        context_vector = self.model.attention(self.gru_cache)\n",
    "        # print(f'{context_vector.size()=}')\n",
    "        output = self.model.classifier(context_vector)\n",
    "        # print(f'{output.size()=}')\n",
    "        output = torch.softmax(output, dim=-1)\n",
    "        # print(f'{output.size()=}')\n",
    "        return output[..., -1].item()\n",
    "    \n",
    "    def forward(self, chunk):\n",
    "        # print(chunk.size())\n",
    "        if chunk.size(-1) < self.melspec_window_size_half:\n",
    "            chunk = F.pad(chunk, (0, self.melspec_window_size_half - chunk.size(-1)))\n",
    "        spec = self.melspec(chunk)\n",
    "        # print(spec.size())\n",
    "        return self.stream(spec)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TaskConfig(hidden_size=32)\n",
    "model = CRNN(config).to(config.device)\n",
    "model.load_state_dict(torch.load('base_3.56e-5.pth', map_location=config.device))\n",
    "\n",
    "stream_model = PewDiePie(model, config, LogMelspec(is_train=False, config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Склеим три трека так, чтобы центральным был трек с ключевым словом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultra_wav.size()=torch.Size([36824])\n"
     ]
    }
   ],
   "source": [
    "index2 = np.where(val_df.label)[0][0]\n",
    "index1 = np.where(~val_df.label)[0][0]\n",
    "index3 = np.where(~val_df.label)[0][1]\n",
    "ultra_wav = torch.cat((val_set[index1]['wav'], val_set[index2]['wav'], val_set[index3]['wav']))\n",
    "print(f'{ultra_wav.size()=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for chunk in torch.split(ultra_wav, 201):\n",
    "    chunk = chunk.view(1, -1)\n",
    "    with torch.inference_mode():\n",
    "        result = stream_model(chunk)\n",
    "    # print(f\"{result=}\")\n",
    "    if result is not None:\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаем, что в центре вероятность будет высокой, а в первой и последней третях низкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(results)), np.array(results))\n",
    "plt.xlabel('chunk')\n",
    "plt.ylabel('prob')\n",
    "_ = plt.title('Вероятность kw в окне в зависимости от чанка')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем для использования в stream.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scripted = torch.jit.script(stream_model)\n",
    "model_scripted.save('kws.pth') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvZ1u7WPFMFA"
   },
   "source": [
    "# Speed up & Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "ald-8mK9FMWV"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "class Timer:\n",
    "\n",
    "    def __init__(self, name: str, verbose=False):\n",
    "        self.name = name\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.t = time.time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self.t = time.time() - self.t\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"{self.name.capitalize()} | Elapsed time : {self.t:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6.0, 3.0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from thop import profile  # !pip install thop\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Conv1d(1, 1, 3, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "        \n",
    "profile(Model(), (torch.randn(1, 1, 4), ))  # -> (6.0 MACs, 3.0 parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "def get_size_in_megabytes(model):\n",
    "    # https://pytorch.org/tutorials/recipes/recipes/dynamic_quantization.html#look-at-model-size\n",
    "    with tempfile.TemporaryFile() as f:\n",
    "        torch.save(model.state_dict(), f)\n",
    "        size = f.tell() / 2**20\n",
    "    return size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Замерим base модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = TaskConfig(hidden_size=32)\n",
    "model = CRNN(config).to(config.device)\n",
    "model.load_state_dict(torch.load('base.pth', map_location=config.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [00:12,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted_probs 12947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12947/12947 [00:03<00:00, 3716.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.556819332944547e-05"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation(model, val_loader, melspec_val, config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10112476348876953\n"
     ]
    }
   ],
   "source": [
    "print(get_size_in_megabytes(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_gru() for <class 'torch.nn.modules.rnn.GRU'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "904608.0 MACs = 452304.0 FLOPs\n"
     ]
    }
   ],
   "source": [
    "two_seconds = melspec_val(torch.randn(1, 1, 2 * 16000))\n",
    "prof = profile(model, two_seconds)\n",
    "print(f'{prof[0]} MACs = {prof[0]/2} FLOPs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Квантизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.quantization\n",
    "qmodel = torch.quantization.quantize_dynamic(model.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102it [00:12,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorted_probs 12947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12947/12947 [00:03<00:00, 3812.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.0169172514490324e-05"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation(qmodel, val_loader, melspec_val, 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики качества ОК!\n",
    "\n",
    "После квантизации перф профайлить не получится, считаем таким же.  \n",
    "Память:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03718090057373047\n"
     ]
    }
   ],
   "source": [
    "print(get_size_in_megabytes(qmodel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compression rate 2.7198040372431835\n"
     ]
    }
   ],
   "source": [
    "print('compression rate', 0.10112476348876953 / 0.03718090057373047)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Дистилляция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
